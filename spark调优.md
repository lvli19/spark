https://blog.csdn.net/junerli/article/details/78729006

# 数据序列化和内存调优

## 序列化有两个库

## 内存调优
* Spark的内存使用基本上可以分为两大类：执行内存和存储内存。
执行内存指的是在shuffle，join，和aggregation计算中使用的内存，存储内存指的是集群中缓存和传播内部数据使用的内存。

在Spark中，执行和存储共享一个统一的区域M。当没有执行内存使用时，存储可以获得全部的可用内存，反之亦然。执行在必要的时候可能会驱逐内存，但只有在总存储内存使用量地域某个阈值R时才会触发。用另一句话来说，R描述在统一内存M中一定不会被驱逐的缓存block子集。由于实现的复杂性，存储不会进行内存驱逐。
    这种设计方案确保了几个令人满意的特性。首先，不使用缓存的应用可以使用全部内存来用于执行，从而消除不必要的磁盘溢出。
    其次，使用缓存的应用程序可以保留最小的不受驱逐的数据库存储空间R。最后，这种方法为各种工作负载提供了合理的开箱即用性能，不需要用户了解内存如何内部划分的专门知识。
    尽管有两个相关的配置，但是通常用户不需要对它们进行调整，因为默认值适用于大多数工作负载:
spark.memory.fraction 代表整体JVM堆内存中M的百分比（默认0.6）。剩余的空间（40%）是为用户数据结构、Spark内部metadata预留的，并在稀疏使用和异常大记录的情况下避免OOM错误。
spark.memory.storageFraction 代表M中R的百分比（默认0.5）。R是M中提供给缓存数据块避免受到执行驱逐的存储空间。
    spark.memory.fraction的值应该设置为可以适配JVM的老年代或终身代的使用。具体可以参考下面的GC章节。
    
* 内存消耗确定

评估数据集所需的内存消耗的最好方法是创建一个RDD，放到内存里，并且通过web UI来查看存储使用量。这个页面会告诉你这个RDD占用了多少内存。

估算某一个特定对象的内存消耗，可以使用SizeEstimator的estimate方法，这对于尝试不同的数据布局来减少内存使用，以及确定一个广播变量将占用每个执行器堆的空间量是很有用的。

## 其他

* 3.3 广播大变量
    使用SparkContext中的广播特性，你可以极大地减少序列化任务的大小，和集群中的启动任务开销。如果你的任务用到了driver中的一个大的对象（例如一个static lookup table），可以考虑将它变为广播变量。Spark将每个任务的序列化大小打印在主服务器上，因此您可以查看它来决定您的任务是否太大;一般来说，大于20kb的任务很可能是值得优化的
* 3.4 数据本地性
    数据本地性对于Spark任务的性能有很大的影响。如果数据和操作的代码在一起，那么计算往往很快。但是由于代码和数据是分离开的，它们中总会有一方要向另一方传递。通常，将序列化的代码从一个地方发送到另一个地方比传输数据块要快，因为代码的大小比数据要小得多。Spark构建了它围绕数据局部性原则的调度。
    数据本地性是数据和处理它的代码之间的距离。下面有基于数据当前维值的几种本地性设置。通过选取最短距离来达成最快的处理速度:
PROCESS_LOCAL 数据在运行代码的同一个JVM中。这是最优选择
NODE_LOCAL 数据在同一个节点上。例如可能在同一个节点上的HDFS上，或是在同一个节点上的另一个处理器中。这比PROCESS_LOCAL稍微慢一点，因为这涉及到进程间的数据通信
NO_PREF 数据可以从任何地方同样快速地访问，并且没有本地偏好
RACK_LOCAL 数据位于相同的服务器机架上。数据在同一个机架上的另一台服务器上，所以需要通过网络发送，通常需要通过一个网关
ANY 数据是在网络上的其他地方，而不是在同一个机架上
    Spark希望把所有的任务都安排在最合适的位置上，但这并不会总是可行的。在没有任何空闲执行机的情况下，Spark会切换到较低的局部性。有两种选择：a. 在同一个服务器上等待CPU空闲，再提交任务 b. 立即在一个其他执行机上开始执行任务，并将数据移动过去
    Spark通常情况下会等待CPU空闲。一旦等待时间超时，它会开始移动数据到较远的空闲CPU上。每个级别之间的等待超时可以单独配置，也可以在一个参数中组合在一起。具体配置参考spark.locality。默认配置通常效果较好，可以根据任务特性来修改这些配置。
