* 来源：子雨大数据 

# 关于Spark

Spark最初由美国加州伯克利大学（UCBerkeley）的AMP（Algorithms, Machines and People）实验室于2009年开发，是基于内存计算的大数据并行计算框架，
可用于 __构建大型的、低延迟的数据分析应用程序__。 Spark在诞生之初属于研究性项目，其诸多核心理念均源自学术研究论文。
2013年，Spark加入Apache孵化器项目后，开始获得迅猛的发展，如今已成为 __Apache软件基金会最重要的三大分布式计算系统开源项目之一（即Hadoop、Spark、Storm）__。

Spark作为大数据计算平台的后起之秀，在2014年打破了Hadoop保持的基准排序（Sort Benchmark）纪录，使用206个节点在23分钟的时间里完成了100TB数据的排序，
而Hadoop则是使用2000个节点在72分钟的时间里完成同样数据的排序。也就是说，Spark仅使用了十分之一的计算资源，获得了比Hadoop快3倍的速度。
新纪录的诞生，使得Spark获得多方追捧，也表明了Spark可以作为一个更加快速、高效的大数据计算平台。


__Spark具有如下几个主要特点：__

* 运行速度快：（从DAG的角度来看）park使用先进的DAG（Directed Acyclic Graph，有向无环图）执行引擎，
以支持循环数据流与内存计算，基于内存的执行速度可比Hadoop MapReduce快上百倍，基于磁盘的执行速度也能快十倍；
* 容易使用：（从语言的角度来看）
Spark支持使用Scala、Java、Python和R语言进行编程，简洁的API设计有助于用户轻松构建并行程序，并且可以通过Spark Shell进行交互式编程；
* 通用性：Spark提供了完整而强大的技术栈，包括SQL查询、流式计算、机器学习和图算法组件， __这些组件可以无缝整合在同一个应用中，足以应对复杂的计算__；
* 运行模式多样：Spark可运行于独立的集群模式中，或者运行于Hadoop中，也可运行于Amazon EC2等云环境中，并且可以访问HDFS、Cassandra、HBase、Hive等多种数据源。

# Spark相对于Hadoop的优势

Hadoop虽然已成为大数据技术的事实标准，但其本身还存在诸多缺陷，
__最主要的缺陷是其MapReduce计算模型延迟过高，无法胜任实时、快速计算的需求，因而只适用于离线批处理的应用场景__。

## 回顾Hadoop的工作流程，可以发现Hadoop存在如下一些缺点：

* 表达能力有限(map reduce)。计算都必须要转化成Map和Reduce两个操作，但这并不适合所有的情况， __难以描述复杂的数据处理过程__；

* 磁盘IO开销大。 每次执行时都需要从 __磁盘__读取数据，并且在计算完成后需要将中间结果写入到磁盘中，IO开销较大；
* 延迟高。一次计算可能需要分解成一系列按顺序执行的MapReduce任务，任务之间的衔接由于涉及到IO开销，会产生较高延迟。而且，在前一个任务执行完成之前，其他任务无法开始， __难以胜任复杂、多阶段的计算任务__。

Spark在借鉴Hadoop MapReduce优点的同时，很好地解决了MapReduce所面临的问题。

## 相比于MapReduce，Spark主要具有如下优点：
* Spark的计算模式也属于MapReduce，但不局限于Map和Reduce操作，还提供了多种数据集操作类型，编程模型比MapReduce更灵活；
* Spark提供了 __内存计算__，中间结果直接放到内存中，带来了更高的 __迭代运算效率__；
* Spark __基于DAG的任务调度执行机制，要优于MapReduce的迭代执行机制__。


Spark最大的特点就是将 __计算数据、中间结果都存储在内存中，大大减少了IO开销__，因而，Spark更适合于迭代运算比较多的数据挖掘与机器学习运算。
使用Hadoop进行迭代计算非常耗资源，因为每次迭代都需要从磁盘中写入、读取中间数据，IO开销大。
而Spark将数据载入内存后，之后的迭代计算都可以直接使用内存中的中间结果作运算，避免了从磁盘中频繁读取数据。

在实际进行开发时，使用Hadoop需要编写不少相对底层的代码，不够高效。相对而言，Spark提供了多种高层次、简洁的API，通常情况下，对于实现相同功能的应用程序，Spark的代码量要比Hadoop少2-5倍。更重要的是，Spark提供了实时交互式编程反馈，可以方便地验证、调整算法。
尽管Spark相对于Hadoop而言具有较大优势，但Spark并不能完全替代Hadoop，主要用于替代Hadoop中的MapReduce计算模型。实际上，Spark已经很好地融入了Hadoop生态圈，并成为其中的重要一员，它可以借助于YARN实现资源调度管理，借助于HDFS实现分布式存储。此外，Hadoop可以使用廉价的、异构的机器来做分布式存储与计算，但是，Spark对硬件的要求稍高一些，对内存与CPU有一定的要求。

# Spark生态系统

### 在实际应用中，大数据处理主要包括以下三个类型：

* 复杂的批量数据处理：时间跨度通常在数十分钟到数小时之间；
* 基于历史数据的交互式查询：时间跨度通常在数十秒到数分钟之间；
* 基于实时数据流的数据处理：时间跨度通常在数百毫秒到数秒之间。

目前已有很多相对成熟的开源软件用于处理以上三种情景，比如， __可以利用Hadoop MapReduce来进行批量数据处理__，可以用 __Impala来进行交互式查询（Impala与Hive相似，但底层引擎不同，提供了实时交互式SQL查询）__， __对于流式数据处理可以采用开源流计算框架Storm__。一些企业可能只会涉及其中部分应用场景，只需部署相应软件即可满足业务需求，但是，对于互联网公司而言，通常会同时存在以上三种场景，就需要同时部署三种不同的软件，这样做难免会带来一些问题：

* 不同场景之间输入输出数据无法做到无缝共享，通常需要进行数据格式的转换；
* 不同的软件需要不同的开发和维护团队，带来了较高的使用成本；
* 比较难以对同一个集群中的各个系统进行统一的资源协调和分配。

Spark的设计遵循“一个软件栈满足不同应用场景”的理念，逐渐形成了一套完整的生态系统，既能够提供内存计算框架，也可以支持SQL即席查询、实时流式计算、机器学习和图计算等。 __Spark可以部署在资源管理器YARN之上，提供一站式的大数据解决方案。因此，Spark所提供的生态系统足以应对上述三种场景，即同时支持批处理、交互式查询和流数据处理。__
现在，Spark生态系统已经成为伯克利数据分析软件栈BDAS（Berkeley Data Analytics Stack）的重要组成部分。BDAS的架构如图所示，从中可以看出，__Spark专注于数据的处理分析，而数据的存储还是要借助于Hadoop分布式文件系统HDFS、Amazon S3等来实现的。 __因此，Spark生态系统可以很好地实现与Hadoop生态系统的兼容，使得现有Hadoop应用程序可以非常容易地迁移到Spark系统中。

__Spark的生态系统主要包含了Spark Core、Spark SQL、Spark Streaming、MLLib和GraphX 等组件__
### 各个组件的具体功能如下：
* Spark Core：Spark Core包含Spark的基本功能，如 __内存计算、任务调度、部署模式、故障恢复、存储管理等__。Spark建立在统一的抽象RDD之上，使其可以以基本一致的方式应对不同的大数据处理场景；通常所说的Apache Spark，就是指Spark Core；
* Spark SQL：Spark SQL允许开发人员直接处理RDD，同时也可查询Hive、HBase等外部数据源。
__Spark SQL的一个重要特点是其能够统一处理关系表和RDD，使得开发人员可以轻松地使用SQL命令进行查询，并进行更复杂的数据分析；__
*  Spark Streaming：Spark Streaming支持 __高吞吐量、可容错处理的实时流数据处理__，其核心思路是 __将流式计算分解成一系列短小的批处理作业__。Spark Streaming支持多种数据输入源，如Kafka、Flume和TCP套接字等；
* MLlib（机器学习）：MLlib提供了常用机器学习算法的实现，包括聚类、分类、回归、协同过滤等，降低了机器学习的门槛，开发人员只要具备一定的理论知识就能进行机器学习的工作；
* GraphX（图计算）：GraphX是Spark中用于图计算的API，可认为是Pregel在Spark上的重写及优化，Graphx性能良好，拥有丰富的功能和运算符，能在海量数据上自如地运行复杂的图算法。
